{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification des documents du procès des groupes américains du tabac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Les données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour avoir une idée sur les données qu'on a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Advertisement/0000136188.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Advertisement/0000435350.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advertisement/0000556056.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Advertisement/0030048095.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advertisement/0030048989.jpg</td>\n",
       "      <td>Advertisement</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       img_path          label\n",
       "0  Advertisement/0000136188.jpg  Advertisement\n",
       "1  Advertisement/0000435350.jpg  Advertisement\n",
       "2  Advertisement/0000556056.jpg  Advertisement\n",
       "3  Advertisement/0030048095.jpg  Advertisement\n",
       "4  Advertisement/0030048989.jpg  Advertisement"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view of the data\n",
    "tabl=pd.read_csv('C:/Users/fzed/Documents/Python Scripts/nlp-labs/tobacco-lab/data/Tobacco3482.csv', sep=',')\n",
    "tabl.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Les differents Classes qu'on a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes : ['Advertisement' 'Email' 'Form' 'Letter' 'Memo' 'News' 'Note' 'Report'\n",
      " 'Resume' 'Scientific']\n"
     ]
    }
   ],
   "source": [
    "print(\"Classes :\",np.unique(tabl.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### La distribution des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Distribution des données')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sn=sns.countplot(data=tabl,y=tabl.label)\n",
    "sn.set_title(\"Distribution des données\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "On remarque que la plupart des données font partie des classes:\n",
    "* Emails\n",
    "* Memos\n",
    "* Lettres\n",
    "* Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Lire les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "path = \"C:/Users/fzed/Documents/Python Scripts/nlp-labs/tobacco-lab/data/Tobacco3482-OCR\"\n",
    "dirs = os.listdir( path )\n",
    "label=[]\n",
    "Data=[]\n",
    "for i,c in enumerate(dirs): \n",
    "    path_classe = path+\"/\"+c\n",
    "    for t in os.listdir(path_classe ) :\n",
    "        os.chdir( path_classe )\n",
    "        label.append(i)\n",
    "        Data.append(open(t,'r',encoding=\"utf8\").read())\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data1=Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PréTraitement(Preprecessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une approche simple consiste à supposer que la plus petite unité d'information dans un texte est le mot . Nous allons donc représenter nos textes sous forme de séquences de mots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Applies some pre-processing on the given text.\n",
    "\n",
    "    Steps :\n",
    "    - Removing HTML tags\n",
    "    - Removing punctuation\n",
    "    - Lowering text\n",
    "    \"\"\"\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    \n",
    "    # remove the characters [\\], ['] , [\"] ,[“] and [‘]\n",
    "    text = re.sub(r\"\\\\\", \"\", text)    \n",
    "    text = re.sub(r\"\\'\", \"\", text)    \n",
    "    text = re.sub(r\"\\\"\", \"\", text)\n",
    "    text = re.sub(r\"\\“\", \"\", text)\n",
    "    text = re.sub(r\"\\‘\", \"\", text)\n",
    "    \n",
    "    # convert text to lowercase\n",
    "    text = text.strip().lower()\n",
    "    \n",
    "    # replace punctuation characters with spaces\n",
    "    filters='!\"\\'#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
    "    translate_dict = dict((c, \" \") for c in filters)\n",
    "    translate_map = str.maketrans(translate_dict)\n",
    "    text = text.translate(translate_map)\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exemple avec la fonction clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"~—Original Message-—\\n\\nFrom: Hsu, Frank\\n\\nSent: ‘Thursday, October 07, 1999 3:25 PM\\nTo: Skinner, lla M.; Parrish, Milton E.\\nCe: Self, David A.; Callicutt, Charlene\\nSubject: FW: Mainstream CO Method\\n\\nHi, According to D. Self's list, you are the desginated reviewers for the attached MS CO. Please\\nforward your comments to Gharlene as early as possible. We need to complete this method\\nlatest by Thursday (10/14). Thanks for your help.\\n\\nFrank\\n\\nVP6CP9ST8NC\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' —original message —  from  hsu  frank  sent  thursday  october 07  1999 3 25 pm to  skinner  lla m   parrish  milton e  ce  self  david a   callicutt  charlene subject  fw  mainstream co method  hi  according to d  selfs list  you are the desginated reviewers for the attached ms co  please forward your comments to gharlene as early as possible  we need to complete this method latest by thursday  10 14   thanks for your help   frank  vp6cp9st8nc'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(Data[500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Netoyer tous les données (Train, Test..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=len(Data)\n",
    "for i in range(l):\n",
    "    Data[i]=clean_text(Data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' —original message —  from  hsu  frank  sent  thursday  october 07  1999 3 25 pm to  skinner  lla m   parrish  milton e  ce  self  david a   callicutt  charlene subject  fw  mainstream co method  hi  according to d  selfs list  you are the desginated reviewers for the attached ms co  please forward your comments to gharlene as early as possible  we need to complete this method latest by thursday  10 14   thanks for your help   frank  vp6cp9st8nc'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verification \n",
    "Data[500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(Data, tabl.label, test_size=0.2)\n",
    "\n",
    "X_dev,X_test,y_dev,y_test=train_test_split(X_test, y_test, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Classifieur bayésien naif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bag of words representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================Bag-of-word representation=====================\n",
      "classification_report : \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Advertisement       0.71      0.19      0.29        27\n",
      "        Email       0.93      0.82      0.87        62\n",
      "         Form       0.63      0.67      0.65        46\n",
      "       Letter       0.48      0.84      0.62        38\n",
      "         Memo       0.53      0.83      0.64        63\n",
      "         News       0.64      0.86      0.73        21\n",
      "         Note       0.00      0.00      0.00        18\n",
      "       Report       1.00      0.10      0.18        31\n",
      "       Resume       1.00      1.00      1.00        15\n",
      "   Scientific       0.69      0.67      0.68        27\n",
      "\n",
      "  avg / total       0.68      0.65      0.60       348\n",
      "\n",
      "==========================================================\n",
      "confusion_matrix : \n",
      " [[ 5  0  3  6  6  7  0  0  0  0]\n",
      " [ 0 51  1  2  8  0  0  0  0  0]\n",
      " [ 0  0 31  4  9  1  0  0  0  1]\n",
      " [ 0  0  0 32  6  0  0  0  0  0]\n",
      " [ 0  0  1  8 52  0  0  0  0  2]\n",
      " [ 1  1  0  0  0 18  0  0  0  1]\n",
      " [ 1  3  8  1  4  1  0  0  0  0]\n",
      " [ 0  0  1 13  9  1  0  3  0  4]\n",
      " [ 0  0  0  0  0  0  0  0 15  0]\n",
      " [ 0  0  4  0  5  0  0  0  0 18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fzed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "## Bag-of-word representation\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(Data)\n",
    "X_train_counts = vectorizer.transform(X_train)\n",
    "X_dev_counts=vectorizer.transform(X_dev)\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_train_counts, y_train)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# YOUR CODE HERE\n",
    "print(\"=====================Bag-of-word representation=====================\")\n",
    "print(\"classification_report : \\n\",classification_report(y_dev, clf.predict(X_dev_counts)))\n",
    "print(\"==========================================================\")\n",
    "print(\"confusion_matrix : \\n\",confusion_matrix(y_dev, clf.predict(X_dev_counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vecteurs Tf-IDF comme caracteristique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Word Level TF-IDF : MAtrice representant les scores tf-idf de chaque terme dans les differents documents.\n",
    "2. N-gram Level TF-IDF : N-grams est la combinaison de N termes . Et cette MAtrice represente les scores tf-idf de N_grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== word level TF/IDF =====================\n",
      "classification_report : \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Advertisement       0.90      0.33      0.49        27\n",
      "        Email       0.98      0.92      0.95        62\n",
      "         Form       0.59      0.70      0.64        46\n",
      "       Letter       0.35      0.76      0.48        38\n",
      "         Memo       0.48      0.84      0.61        63\n",
      "         News       1.00      0.05      0.09        21\n",
      "         Note       0.00      0.00      0.00        18\n",
      "       Report       1.00      0.03      0.06        31\n",
      "       Resume       1.00      1.00      1.00        15\n",
      "   Scientific       0.93      0.52      0.67        27\n",
      "\n",
      "  avg / total       0.71      0.61      0.56       348\n",
      "\n",
      "==========================================================\n",
      "confusion_matrix : \n",
      " [[ 9  0  7  6  5  0  0  0  0  0]\n",
      " [ 0 57  0  1  4  0  0  0  0  0]\n",
      " [ 0  0 32  2 12  0  0  0  0  0]\n",
      " [ 0  0  0 29  9  0  0  0  0  0]\n",
      " [ 0  0  1  9 53  0  0  0  0  0]\n",
      " [ 1  0  0 17  2  1  0  0  0  0]\n",
      " [ 0  1 10  0  7  0  0  0  0  0]\n",
      " [ 0  0  1 16 12  0  0  1  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 15  0]\n",
      " [ 0  0  3  3  7  0  0  0  0 14]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fzed\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# word level TF/IDF\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# YOUR CODE HERE\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "# tf_transformer = TfidfTransformer().fit(Data)\n",
    "tfidf_vect.fit(Data)\n",
    "X_train_tf = tfidf_vect.transform(X_train)\n",
    "X_dev_tf = tfidf_vect.transform(X_dev)\n",
    "# model training \n",
    "clf_tf = MultinomialNB()\n",
    "clf_tf.fit(X_train_tf, y_train)\n",
    "#\n",
    "# print(\"le score sur les données de validation\",clf.score(X_dev_tf, y_dev))\n",
    "#\n",
    "print(\"===================== word level TF/IDF =====================\")\n",
    "print(\"classification_report : \\n\",classification_report(y_dev, clf_tf.predict(X_dev_tf)))\n",
    "print(\"==========================================================\")\n",
    "print(\"confusion_matrix : \\n\",confusion_matrix(y_dev, clf_tf.predict(X_dev_tf)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== ngram level tf_idf =====================\n",
      "classification_report : \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Advertisement       1.00      0.48      0.65        27\n",
      "        Email       0.89      0.92      0.90        62\n",
      "         Form       0.69      0.67      0.68        46\n",
      "       Letter       0.51      0.66      0.57        38\n",
      "         Memo       0.47      0.87      0.61        63\n",
      "         News       0.94      0.76      0.84        21\n",
      "         Note       1.00      0.17      0.29        18\n",
      "       Report       0.88      0.23      0.36        31\n",
      "       Resume       1.00      1.00      1.00        15\n",
      "   Scientific       0.78      0.52      0.62        27\n",
      "\n",
      "  avg / total       0.76      0.68      0.66       348\n",
      "\n",
      "==========================================================\n",
      "confusion_matrix : \n",
      " [[13  2  4  3  5  0  0  0  0  0]\n",
      " [ 0 57  1  2  2  0  0  0  0  0]\n",
      " [ 0  0 31  3 11  0  0  0  0  1]\n",
      " [ 0  2  0 25 11  0  0  0  0  0]\n",
      " [ 0  1  0  7 55  0  0  0  0  0]\n",
      " [ 0  1  0  1  2 16  0  0  0  1]\n",
      " [ 0  0  2  0 13  0  3  0  0  0]\n",
      " [ 0  1  2  7 11  1  0  7  0  2]\n",
      " [ 0  0  0  0  0  0  0  0 15  0]\n",
      " [ 0  0  5  1  6  0  0  1  0 14]]\n"
     ]
    }
   ],
   "source": [
    "#ngram level tf_idf\n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(Data)\n",
    "X_train_tf_ngram = tfidf_vect_ngram.transform(X_train)\n",
    "X_dev_tf_ngram = tfidf_vect_ngram.transform(X_dev)\n",
    "# bayes\n",
    "clf_ngram = MultinomialNB()\n",
    "clf_ngram.fit(X_train_tf_ngram, y_train)\n",
    "#\n",
    "# print(\"le score sur les données de validation\",clf.score(X_dev_tf_ngram, y_dev))\n",
    "#\n",
    "print(\"===================== ngram level tf_idf =====================\")\n",
    "print(\"classification_report : \\n\",classification_report(y_dev, clf_ngram.predict(X_dev_tf_ngram)))\n",
    "print(\"==========================================================\")\n",
    "print(\"confusion_matrix : \\n\",confusion_matrix(y_dev, clf_ngram.predict(X_dev_tf_ngram)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D'après le rapport de classification on constate que le model est plutot modeste , en analysant les resultats ,on peut remarquer des anomalie , comme par exemple  dans la classe \"Report\" où toutes les metriques sont égales à 0 dans les deux preières representation(Bag of words et word level tf_IDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimization des hyper parametres; "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "on peut avoir de meilleur resultats , par rapport au premier model\"bayesien\"\n",
    ",en jouent avec les hyper parametres:\n",
    "    * pour le classifieur : le parametre alpha\n",
    "    * max_features, max_df, min_df,ngram orders pour le TfIDF transformer\n",
    "ces parametres peuvent etre optimiser en utilisant Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters:\n",
      "{'clf__alpha': (0.01, 0.05, 0.07, 0.1, 0.5, 1.0),\n",
      " 'vect__max_df': (0.1, 0.5, 0.9),\n",
      " 'vect__max_features': (1000, 2000, 3000)}\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   36.6s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 154.734s\n",
      "\n",
      "Best score: 0.721\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.07\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__max_features: 2000\n"
     ]
    }
   ],
   "source": [
    "# Hyperameters optimization with GridSearchCV = parallel processing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "])\n",
    "\n",
    "\n",
    "parameters = {\n",
    "    'vect__max_df':(0.1, 0.5, 0.9),\n",
    "    'vect__max_features':(1000, 2000, 3000),\n",
    "    'clf__alpha' :(0.01,0.05,0.07,0.1,0.5,1.0)\n",
    "#     'clf__ngram' :(2,3,5,7,10)\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, verbose=2)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "Advertisement       0.68      0.65      0.67        23\n",
      "        Email       0.87      0.95      0.91        56\n",
      "         Form       0.73      0.75      0.74        44\n",
      "       Letter       0.70      0.59      0.64        68\n",
      "         Memo       0.53      0.71      0.60        59\n",
      "         News       0.58      0.79      0.67        14\n",
      "         Note       0.50      0.26      0.34        23\n",
      "       Report       0.53      0.45      0.49        20\n",
      "       Resume       1.00      1.00      1.00        13\n",
      "   Scientific       0.78      0.62      0.69        29\n",
      "\n",
      "  avg / total       0.69      0.69      0.68       349\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[15,  2,  1,  0,  3,  1,  1,  0,  0,  0],\n",
       "       [ 0, 53,  1,  0,  2,  0,  0,  0,  0,  0],\n",
       "       [ 2,  0, 33,  0,  2,  0,  4,  3,  0,  0],\n",
       "       [ 0,  1,  1, 40, 19,  4,  0,  2,  0,  1],\n",
       "       [ 1,  2,  1,  8, 42,  0,  1,  1,  0,  3],\n",
       "       [ 1,  0,  1,  0,  0, 11,  0,  1,  0,  0],\n",
       "       [ 1,  3,  2,  3,  7,  1,  6,  0,  0,  0],\n",
       "       [ 1,  0,  2,  3,  2,  2,  0,  9,  0,  1],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0, 13,  0],\n",
       "       [ 1,  0,  3,  3,  3,  0,  0,  1,  0, 18]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_estimator = grid_search.best_estimator_\n",
    "\n",
    "# Affichage du rapport de classification et de la matrice de confusion\n",
    "print(classification_report(y_test, best_estimator.predict(X_test)))\n",
    "confusion_matrix(y_test, best_estimator.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Classifieur : Convolutional Neural Network (CNN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fzed\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import os\n",
    "import nn_utils \n",
    "from keras.layers import Dense, Embedding, Input\n",
    "from keras.layers import GRU, Dropout, MaxPooling1D, Conv1D, Flatten,BatchNormalization\n",
    "from keras.models import Model\n",
    "import numpy as np\n",
    "import itertools\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import (classification_report, \n",
    "                             precision_recall_fscore_support, \n",
    "                             accuracy_score)\n",
    "\n",
    "from keras.preprocessing import text, sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters    TrainingHistory\n",
    "MAX_FEATURES =1000 \n",
    "MAX_TEXT_LENGTH =1000 \n",
    "EMBED_SIZE  =100 \n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "VALIDATION_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Advertisement' 'Email' 'Form' 'Letter' 'Memo' 'News' 'Note' 'Report'\n",
      " 'Resume' 'Scientific']\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 100)         100000    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1000, 100)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1000, 128)         64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 333, 128)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 333, 128)          1332      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 333, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 42624)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                426250    \n",
      "=================================================================\n",
      "Total params: 591,710\n",
      "Trainable params: 591,044\n",
      "Non-trainable params: 666\n",
      "_________________________________________________________________\n",
      "Train on 2785 samples, validate on 348 samples\n",
      "Epoch 1/10\n",
      "2785/2785 [==============================] - 113s 41ms/step - loss: 2.5444 - acc: 0.3537 - val_loss: 1.3414 - val_acc: 0.5374\n",
      "Epoch 2/10\n",
      "2785/2785 [==============================] - 111s 40ms/step - loss: 0.6517 - acc: 0.7978 - val_loss: 1.0131 - val_acc: 0.6580\n",
      "Epoch 3/10\n",
      "2785/2785 [==============================] - 115s 41ms/step - loss: 0.2886 - acc: 0.9285 - val_loss: 0.8769 - val_acc: 0.7184\n",
      "Epoch 4/10\n",
      "2785/2785 [==============================] - 111s 40ms/step - loss: 0.1494 - acc: 0.9670 - val_loss: 0.8137 - val_acc: 0.7241\n",
      "Epoch 5/10\n",
      "2785/2785 [==============================] - 111s 40ms/step - loss: 0.0960 - acc: 0.9759 - val_loss: 0.8004 - val_acc: 0.7385\n",
      "Epoch 6/10\n",
      "2785/2785 [==============================] - 111s 40ms/step - loss: 0.0732 - acc: 0.9838 - val_loss: 0.8466 - val_acc: 0.7443\n",
      "Epoch 7/10\n",
      "2785/2785 [==============================] - 111s 40ms/step - loss: 0.0614 - acc: 0.9828 - val_loss: 0.8952 - val_acc: 0.7385\n",
      "Epoch 8/10\n",
      "2785/2785 [==============================] - 112s 40ms/step - loss: 0.0462 - acc: 0.9871 - val_loss: 0.9155 - val_acc: 0.7328\n",
      "Epoch 9/10\n",
      "2785/2785 [==============================] - 111s 40ms/step - loss: 0.0466 - acc: 0.9885 - val_loss: 0.9406 - val_acc: 0.7213\n",
      "Epoch 10/10\n",
      "2785/2785 [==============================] - 111s 40ms/step - loss: 0.0342 - acc: 0.9914 - val_loss: 0.9088 - val_acc: 0.7299\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fd02eca3c8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_train_test(train_raw_text, test_raw_text,dev_raw_text):\n",
    "    \n",
    "    tokenizer = text.Tokenizer(num_words=MAX_FEATURES)\n",
    "\n",
    "    tokenizer.fit_on_texts(list(train_raw_text))\n",
    "    dev_tokenized = tokenizer.texts_to_sequences(dev_raw_text)\n",
    "    train_tokenized = tokenizer.texts_to_sequences(train_raw_text)\n",
    "    test_tokenized = tokenizer.texts_to_sequences(test_raw_text)\n",
    "    return (sequence.pad_sequences(train_tokenized, maxlen=MAX_TEXT_LENGTH), \n",
    "           sequence.pad_sequences(test_tokenized, maxlen=MAX_TEXT_LENGTH),\n",
    "           sequence.pad_sequences(dev_tokenized, maxlen=MAX_TEXT_LENGTH))\n",
    "\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\n",
    "    inp = Input(shape=(MAX_TEXT_LENGTH,))\n",
    "    model = Embedding(MAX_TEXT_LENGTH, EMBED_SIZE)(inp)\n",
    "    model = Dropout(0.2)(model)\n",
    "   \n",
    "    \n",
    "    model = Conv1D(filters=128, kernel_size=5, padding='same', activation='relu')(model)\n",
    "    model = MaxPooling1D(pool_size=3)(model)\n",
    "    model = BatchNormalization(axis=1)(model)\n",
    "    model = Dropout(0.3)(model)\n",
    "    \n",
    "    model = Flatten()(model)\n",
    "    model = Dense(10, activation=\"softmax\")(model)\n",
    "    model = Model(inputs=inp, outputs=model)\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get the list of different classes\n",
    "CLASSES_LIST = np.unique(y_train)\n",
    "n_out = len(CLASSES_LIST)\n",
    "print(CLASSES_LIST)\n",
    "\n",
    "# Convert clas string to index\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(CLASSES_LIST)\n",
    "y_train_t = le.transform(y_train) \n",
    "y_dev_t=le.transform(y_dev) \n",
    "y_test_t = le.transform(y_test) \n",
    "train_y_cat = np_utils.to_categorical(y_train_t, n_out)\n",
    "dev_y_cat = np_utils.to_categorical(y_dev_t, n_out)\n",
    "test_y_cat = np_utils.to_categorical(y_test_t, n_out)\n",
    "\n",
    "# get the textual data in the correct format for NN\n",
    "x_vec_train, x_vec_test,x_vec_dev = get_train_test(X_train, X_test,X_dev)\n",
    "# print(len(x_vec_train), len(x_vec_test))\n",
    "\n",
    "# define the NN topology\n",
    "model = get_model()\n",
    "\n",
    "# Define training procedure\n",
    "# history = TrainingHistory(x_vec_test, y_test, CLASSES_LIST)\n",
    "model.fit(x_vec_train, train_y_cat,\n",
    "              batch_size=BATCH_SIZE,\n",
    "              epochs=EPOCHS, verbose=1,\n",
    "               validation_data=(x_vec_dev,dev_y_cat)\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer les prediction du model en fonction des classes \n",
    "y_predicted=model.predict(x_vec_test)\n",
    "y_predicted.shape\n",
    "y_pred=[]\n",
    "for i in range(y_predicted.shape[0]):\n",
    "    maxi=0\n",
    "    maxi= np.argmax(y_predicted[i])\n",
    "    y_pred.append(CLASSES_LIST[maxi])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7134670487106017\n",
      "p r f1 71.3 71.35 71.347\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Advertisement       0.52      0.48      0.50        23\n",
      "        Email       0.92      0.96      0.94        56\n",
      "         Form       0.69      0.77      0.73        44\n",
      "       Letter       0.78      0.66      0.71        68\n",
      "         Memo       0.72      0.75      0.73        59\n",
      "         News       0.70      0.50      0.58        14\n",
      "         Note       0.62      0.70      0.65        23\n",
      "       Report       0.24      0.30      0.27        20\n",
      "       Resume       1.00      1.00      1.00        13\n",
      "   Scientific       0.70      0.66      0.68        29\n",
      "\n",
      "  avg / total       0.72      0.71      0.71       349\n",
      "\n",
      "confusion_matrix : \n",
      " [[11  1  3  0  1  0  5  2  0  0]\n",
      " [ 0 54  0  0  2  0  0  0  0  0]\n",
      " [ 2  2 34  1  0  0  3  1  0  1]\n",
      " [ 2  2  2 45  9  0  0  8  0  0]\n",
      " [ 0  0  0  7 44  1  1  3  0  3]\n",
      " [ 1  0  1  0  1  7  0  3  0  1]\n",
      " [ 2  0  3  0  2  0 16  0  0  0]\n",
      " [ 3  0  3  4  0  1  0  6  0  3]\n",
      " [ 0  0  0  0  0  0  0  0 13  0]\n",
      " [ 0  0  3  1  2  1  1  2  0 19]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "p, r, f1, s = precision_recall_fscore_support(y_test, y_pred, \n",
    "                                              average='micro',\n",
    "                                              labels=[x for x in \n",
    "                                                      np.unique(y_train) \n",
    "                                                      if x not in ['CSDECMOTV']])\n",
    "\n",
    "print('p r f1 %.1f %.2f %.3f' % (np.average(p, weights=s)*100.0, \n",
    "                                 np.average(r, weights=s)*100.0, \n",
    "                                 np.average(f1, weights=s)*100.0))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred, labels=[x for x in \n",
    "                                                       np.unique(y_train) \n",
    "                                                       if x not in ['CSDECMOTV']]))\n",
    "\n",
    "print(\"confusion_matrix : \\n\",confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multi Layer Perceptron (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.04635497\n",
      "Validation score: 0.749104\n",
      "Iteration 2, loss = 1.14282390\n",
      "Validation score: 0.806452\n",
      "Iteration 3, loss = 1.03219721\n",
      "Validation score: 0.799283\n",
      "Iteration 4, loss = 1.00411970\n",
      "Validation score: 0.784946\n",
      "Iteration 5, loss = 0.98185861\n",
      "Validation score: 0.792115\n",
      "Validation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=1.2, batch_size=50, beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_mlp = MLPClassifier(alpha = 1.2, early_stopping=True, batch_size=50, verbose=1)\n",
    "model_mlp.fit(X_train_counts, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================== MLP  =====================\n",
      "classification_report : \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Advertisement       0.83      0.56      0.67        27\n",
      "        Email       0.91      0.97      0.94        62\n",
      "         Form       0.76      0.96      0.85        46\n",
      "       Letter       0.57      0.76      0.65        38\n",
      "         Memo       0.87      0.92      0.89        63\n",
      "         News       0.86      0.86      0.86        21\n",
      "         Note       0.71      0.56      0.63        18\n",
      "       Report       0.78      0.45      0.57        31\n",
      "       Resume       1.00      1.00      1.00        15\n",
      "   Scientific       0.80      0.59      0.68        27\n",
      "\n",
      "  avg / total       0.81      0.80      0.79       348\n",
      "\n",
      "==========================================================\n",
      "confusion_matrix : \n",
      " [[15  1  3  4  0  0  3  0  0  1]\n",
      " [ 1 60  0  1  0  0  0  0  0  0]\n",
      " [ 0  0 44  1  0  0  1  0  0  0]\n",
      " [ 0  0  1 29  7  0  0  1  0  0]\n",
      " [ 0  1  0  3 58  0  0  0  0  1]\n",
      " [ 1  1  0  0  0 18  0  1  0  0]\n",
      " [ 0  3  4  1  0  0 10  0  0  0]\n",
      " [ 1  0  2 11  0  1  0 14  0  2]\n",
      " [ 0  0  0  0  0  0  0  0 15  0]\n",
      " [ 0  0  4  1  2  2  0  2  0 16]]\n"
     ]
    }
   ],
   "source": [
    "print(\"===================== MLP  =====================\")\n",
    "print(\"classification_report : \\n\",classification_report(y_dev, model_mlp.predict(X_dev_counts)))\n",
    "print(\"==========================================================\")\n",
    "print(\"confusion_matrix : \\n\",confusion_matrix(y_dev,model_mlp.predict(X_dev_counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut toujours ameliorer les models , en jouent sur plusieurs parametres afin d'avoir de meilleurs resultats:\n",
    "\n",
    "    *batch_size\n",
    "    *nombre d'epochs\n",
    "    *alpha (MLP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
